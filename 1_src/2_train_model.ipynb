{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((224, 224)),  # 調整到模型需求的輸入大小\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 常見正規化數值\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/train', transform=transform)\n",
    "valid_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/vali_20k', transform=transform)\n",
    "test_ds  = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/test_50k', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(train_ds.class_to_idx)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=False, num_classes=NUM_CLASSES)\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=False)\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, NUM_CLASSES)\n",
    "batch_norm = False  # 預設為 False\n",
    "init_weights = True  # 預設為 True\n",
    "\n",
    "####################### 需要額外處理 #######################\n",
    "googlenet = models.googlenet(pretrained=False, aux_logits=True, transform_input=False)# 3. GoogleLeNet (Inception v1)\n",
    "googlenet.fc = nn.Linear(googlenet.fc.in_features, NUM_CLASSES)\n",
    "googlenet.aux1.fc2 = nn.Linear(googlenet.aux1.fc2.in_features, NUM_CLASSES)  # 修改輔助分類器\n",
    "googlenet.aux2.fc2 = nn.Linear(googlenet.aux2.fc2.in_features, NUM_CLASSES)\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False, zero_init_residual=False)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "squeezenet = models.squeezenet1_0(pretrained=False, num_classes=NUM_CLASSES)\n",
    "squeezenet.classifier[1] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=False, width_mult=1.0, round_nearest=8)\n",
    "mobilenet_v2.classifier[1] = nn.Linear(mobilenet_v2.classifier[1].in_features, NUM_CLASSES)\n",
    "\n",
    "efficientnet_b0 = models.efficientnet_b0(pretrained=False)\n",
    "efficientnet_b0.classifier[1] = nn.Linear(efficientnet_b0.classifier[1].in_features, NUM_CLASSES)\n",
    "\n",
    "swin_transformer = models.swin_t(pretrained=False, num_classes=NUM_CLASSES)\n",
    "swin_transformer.head = nn.Linear(swin_transformer.head.in_features, NUM_CLASSES)\n",
    "embed_dim = 96  # 預設\n",
    "depths = [2, 2, 6, 2]  # 預設\n",
    "num_heads = [3, 6, 12, 24]  # 預設\n",
    "window_size = 7  # 預設\n",
    "drop_path_rate = 0.1  # 預設\n",
    "ape = False  # 預設\n",
    "patch_norm = True  # 預設\n",
    "\n",
    "xception = create_model('xception', pretrained=False, num_classes=NUM_CLASSES, drop_rate=0.2)\n",
    "\n",
    "convnext_tiny = create_model('convnext_tiny', pretrained=False, num_classes=NUM_CLASSES, drop_path_rate=0.1)\n",
    "\n",
    "mnasnet = models.mnasnet1_0(pretrained=False)\n",
    "mnasnet.classifier[1] = nn.Linear(mnasnet.classifier[1].in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = alexnet\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  958941\n",
      "Number of test samples:  49500\n",
      "Detected Classes are:  {'dry_asphalt_severe': 0, 'dry_asphalt_slight': 1, 'dry_asphalt_smooth': 2, 'dry_concrete_severe': 3, 'dry_concrete_slight': 4, 'dry_concrete_smooth': 5, 'dry_gravel': 6, 'dry_mud': 7, 'fresh_snow': 8, 'ice': 9, 'melted_snow': 10, 'water_asphalt_severe': 11, 'water_asphalt_slight': 12, 'water_asphalt_smooth': 13, 'water_concrete_severe': 14, 'water_concrete_slight': 15, 'water_concrete_smooth': 16, 'water_gravel': 17, 'water_mud': 18, 'wet_asphalt_severe': 19, 'wet_asphalt_slight': 20, 'wet_asphalt_smooth': 21, 'wet_concrete_severe': 22, 'wet_concrete_slight': 23, 'wet_concrete_smooth': 24, 'wet_gravel': 25, 'wet_mud': 26}\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3746/3746 [30:29<00:00,  2.05it/s, loss=1.07] \n"
     ]
    }
   ],
   "source": [
    "# 儲存訓練損失與準確度\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# 訓練\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # 使用 tqdm 包裹 train_loader\n",
    "    train_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "    for step, (x, y) in train_bar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model(x)\n",
    "        loss = loss_func(output, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累計損失與準確度\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        correct_train += (preds == y).sum().item()\n",
    "        total_train += y.size(0)\n",
    "\n",
    "        # 更新進度條\n",
    "        train_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    # 計算單個 epoch 的平均損失與準確度\n",
    "    epoch_loss = train_loss / len(train_ds)\n",
    "    epoch_accuracy = correct_train / total_train\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# 繪製損失與準確度圖表\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 損失圖\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# 準確度圖\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: AlexNet_ACC0.54_E1_BS256_LR1e-03_T00h30m46s.pt\n"
     ]
    }
   ],
   "source": [
    "# 測試準確度\n",
    "test_x, test_y = next(iter(test_loader))\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "test_output = model(test_x).argmax(1)\n",
    "accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "\n",
    "# 模型名稱\n",
    "model_name = type(model).__name__\n",
    "\n",
    "# 檔案名稱包含訓練時間\n",
    "file_name = f\"{model_name}_ACC{accuracy:.2f}_E{EPOCHS}_BS{BATCH_SIZE}_LR{LEARNING_RATE:.0e}_T{int(training_time // 3600):02d}h{int((training_time % 3600) // 60):02d}m{int(training_time % 60):02d}s.pt\"\n",
    "\n",
    "# 儲存路徑\n",
    "save_path = os.path.join('../2_results/0_weight', file_name)\n",
    "torch.save(model, save_path)\n",
    "\n",
    "print(f\"Model saved as: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
