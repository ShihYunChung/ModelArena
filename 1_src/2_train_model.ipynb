{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((224, 224)),  # 調整到模型需求的輸入大小\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 常見正規化數值\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/train', transform=transform)\n",
    "valid_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/vali_20k', transform=transform)\n",
    "test_ds  = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/test_50k', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YunChung\\miniconda3\\envs\\eenv\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(str(Path(\"0_utils\") ))\n",
    "\n",
    "# 匯入模型初始化模組\n",
    "from models_initializer import initialize_all_models\n",
    "\n",
    "# 初始化模型\n",
    "NUM_CLASSES = len(train_ds.class_to_idx)\n",
    "models = initialize_all_models(NUM_CLASSES, pretrained=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model           | 參數                         |\n",
    "|:----------------|:-----------------------------|\n",
    "| alexnet         | None                         |\n",
    "| vgg16           | dropout_rate, use_batch_norm |\n",
    "| googlenet       | aux_logits, transform_input  |\n",
    "| resnet18        | None                         |\n",
    "| squeezenet      | None                         |\n",
    "| mobilenet_v2    | width_mult, round_nearest    |\n",
    "| efficientnet_b0 | None                         |\n",
    "| swin_t          | drop_path_rate               |\n",
    "| xception        | dropout_rate                 |\n",
    "| convnext_tiny   | drop_path_rate               |\n",
    "| mnasnet         | None                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = alexnet\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 213/3746 [04:56<1:22:31,  1.40s/it, loss=1.21] "
     ]
    }
   ],
   "source": [
    "# 儲存訓練損失與準確度\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# 訓練\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # 使用 tqdm 包裹 train_loader\n",
    "    train_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "    for step, (x, y) in train_bar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model(x)\n",
    "        loss = loss_func(output, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累計損失與準確度\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        correct_train += (preds == y).sum().item()\n",
    "        total_train += y.size(0)\n",
    "\n",
    "        # 更新進度條\n",
    "        train_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    # 計算單個 epoch 的平均損失與準確度\n",
    "    epoch_loss = train_loss / len(train_ds)\n",
    "    epoch_accuracy = correct_train / total_train\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# 繪製損失與準確度圖表\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 損失圖\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# 準確度圖\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: AlexNet_ACC0.54_E1_BS256_LR1e-03_T00h30m46s.pt\n"
     ]
    }
   ],
   "source": [
    "# 測試準確度\n",
    "test_x, test_y = next(iter(test_loader))\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "test_output = model(test_x).argmax(1)\n",
    "accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "\n",
    "# 模型名稱\n",
    "model_name = type(model).__name__\n",
    "\n",
    "# 檔案名稱包含訓練時間\n",
    "file_name = f\"{model_name}_ACC{accuracy:.2f}_E{EPOCHS}_BS{BATCH_SIZE}_LR{LEARNING_RATE:.0e}_T{int(training_time // 3600):02d}h{int((training_time % 3600) // 60):02d}m{int(training_time % 60):02d}s.pt\"\n",
    "\n",
    "# 儲存路徑\n",
    "save_path = os.path.join('../2_results/0_weight', file_name)\n",
    "torch.save(model, save_path)\n",
    "\n",
    "print(f\"Model saved as: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
