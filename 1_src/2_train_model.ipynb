{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((224, 224)),  # 調整到模型需求的輸入大小\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 常見正規化數值\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/train', transform=transform)\n",
    "valid_ds = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/vali_20k', transform=transform)\n",
    "test_ds  = torchvision.datasets.ImageFolder('../0_data/0_rawDataSet/RSCD dataset-1million/test_50k', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(train_ds.class_to_idx)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=False, num_classes=NUM_CLASSES)\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=False)\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, NUM_CLASSES)\n",
    "batch_norm = False  # 預設為 False\n",
    "init_weights = True  # 預設為 True\n",
    "\n",
    "####################### 需要額外處理 #######################\n",
    "googlenet = models.googlenet(pretrained=False, aux_logits=True, transform_input=False)# 3. GoogleLeNet (Inception v1)\n",
    "googlenet.fc = nn.Linear(googlenet.fc.in_features, NUM_CLASSES)\n",
    "googlenet.aux1.fc2 = nn.Linear(googlenet.aux1.fc2.in_features, NUM_CLASSES)  # 修改輔助分類器\n",
    "googlenet.aux2.fc2 = nn.Linear(googlenet.aux2.fc2.in_features, NUM_CLASSES)\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False, zero_init_residual=False)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "squeezenet = models.squeezenet1_0(pretrained=False, num_classes=NUM_CLASSES)\n",
    "squeezenet.classifier[1] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=False, width_mult=1.0, round_nearest=8)\n",
    "mobilenet_v2.classifier[1] = nn.Linear(mobilenet_v2.classifier[1].in_features, NUM_CLASSES)\n",
    "\n",
    "efficientnet_b0 = models.efficientnet_b0(pretrained=False)\n",
    "efficientnet_b0.classifier[1] = nn.Linear(efficientnet_b0.classifier[1].in_features, NUM_CLASSES)\n",
    "\n",
    "swin_transformer = models.swin_t(pretrained=False, num_classes=NUM_CLASSES)\n",
    "swin_transformer.head = nn.Linear(swin_transformer.head.in_features, NUM_CLASSES)\n",
    "embed_dim = 96  # 預設\n",
    "depths = [2, 2, 6, 2]  # 預設\n",
    "num_heads = [3, 6, 12, 24]  # 預設\n",
    "window_size = 7  # 預設\n",
    "drop_path_rate = 0.1  # 預設\n",
    "ape = False  # 預設\n",
    "patch_norm = True  # 預設\n",
    "\n",
    "xception = create_model('xception', pretrained=False, num_classes=NUM_CLASSES, drop_rate=0.2)\n",
    "\n",
    "convnext_tiny = create_model('convnext_tiny', pretrained=False, num_classes=NUM_CLASSES, drop_path_rate=0.1)\n",
    "\n",
    "mnasnet = models.mnasnet1_0(pretrained=False)\n",
    "mnasnet.classifier[1] = nn.Linear(mnasnet.classifier[1].in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = alexnet\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  958941\n",
      "Number of test samples:  49500\n",
      "Detected Classes are:  {'dry_asphalt_severe': 0, 'dry_asphalt_slight': 1, 'dry_asphalt_smooth': 2, 'dry_concrete_severe': 3, 'dry_concrete_slight': 4, 'dry_concrete_smooth': 5, 'dry_gravel': 6, 'dry_mud': 7, 'fresh_snow': 8, 'ice': 9, 'melted_snow': 10, 'water_asphalt_severe': 11, 'water_asphalt_slight': 12, 'water_asphalt_smooth': 13, 'water_concrete_severe': 14, 'water_concrete_slight': 15, 'water_concrete_smooth': 16, 'water_gravel': 17, 'water_mud': 18, 'wet_asphalt_severe': 19, 'wet_asphalt_slight': 20, 'wet_asphalt_smooth': 21, 'wet_concrete_severe': 22, 'wet_concrete_slight': 23, 'wet_concrete_smooth': 24, 'wet_gravel': 25, 'wet_mud': 26}\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3746/3746 [28:50<00:00,  2.16it/s, loss=1.11] \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train samples: \", len(train_ds))\n",
    "print(\"Number of test samples: \", len(test_ds))\n",
    "print(\"Detected Classes are: \", train_ds.class_to_idx) \n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "test_loader = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Train\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    # 使用 tqdm 包裹 train_loader\n",
    "    train_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "    for step, (x, y) in train_bar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        b_x = Variable(x)\n",
    "        b_y = Variable(y)\n",
    "\n",
    "        # Forward\n",
    "        output = model(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "\n",
    "        # Train loss\n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "\n",
    "        # 更新 tqdm 的描述信息\n",
    "        train_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        # # Test\n",
    "        # if step % 50 == 0:\n",
    "        #     test_x, test_y = next(iter(test_loader))\n",
    "        #     test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "        #     test_output = model(test_x).argmax(1)\n",
    "        #     accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "\n",
    "        #     print(f\"Step {step}: Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = next(iter(test_loader))\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "test_output = model(test_x).argmax(1)\n",
    "accuracy = (test_output == test_y).sum().item() / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = type(model).__name__ \n",
    "file_name = f\"{model_name}_{accuracy:.2f}_epoch{epoch+1}_batchSize{BATCH_SIZE}_lr{LEARNING_RATE:.0e}.pt\"\n",
    "save_path = os.path.join('../2_results/0_weight', file_name)\n",
    "torch.save(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
